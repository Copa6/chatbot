{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up working directory information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = os.getcwd()\n",
    "data_directory = os.path.join(working_directory, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(os.path.join(data_directory, 'movie_lines.txt'), encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "conversations = open(os.path.join(data_directory, 'movie_conversations.txt'), encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_separator = \" +++$+++ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!',\n",
       " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!',\n",
       " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.',\n",
       " 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?',\n",
       " \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize top five lines\n",
    "lines[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ids to the line said by character\n",
    "id_to_line = {}\n",
    "for line in lines:\n",
    "    _line = line.split(data_separator)\n",
    "    if len(_line) == 5:\n",
    "        id_to_line[_line[0]] = _line[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\"]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize top 5 conversations\n",
    "conversations[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_characters = r\"['\\s\\[\\]]\"\n",
    "conversations_ids = [re.sub(junk_characters, \"\", conv.split(data_separator)[-1]).split(\",\") for  conv in conversations[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L194', 'L195', 'L196', 'L197']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Questions and Answers data\n",
    "In conversations_ids, the list represents [Q, A, Q, A...] - Use this structure to create QnA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for conv in conversations_ids:\n",
    "    for i in range(len(conv)-1):\n",
    "        questions.append(id_to_line[conv[i]])\n",
    "        answers.append(id_to_line[conv[i+1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common contractions\n",
    "common_contractions = {\n",
    "    r\"i'm\": \"i am\",\n",
    "    r\"he's\": \"he is\",\n",
    "    r\"she's\": \"she is\",\n",
    "    r\"that's\": \"that is\",\n",
    "    r\"what's\": \"what is\",\n",
    "    r\"where's\": \"where is\",\n",
    "    r\"\\'ll\": \" will\",\n",
    "    r\"\\'ve\": \" have\",\n",
    "    r\"\\'re\": \" are\",\n",
    "    r\"\\'d\": \" would\",\n",
    "    r\"won't\": \"will not\",\n",
    "    r\"can't\": \"can not\",\n",
    "    r\"&\": \"and\",\n",
    "    r\"[$()\\\"#/@;:<>{}+=-`|.?,\\'*%_\\[\\]]|(-)+\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # replace common contractions\n",
    "    for contraction, replacement in common_contractions.items():\n",
    "        text = re.sub(contraction, replacement, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_questions = [clean_text(q) for q in questions]\n",
    "cleaned_answers = [clean_text(a) for a in answers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Removing infrequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = defaultdict(int)\n",
    "max_word_count = 1\n",
    "for q,a in zip(cleaned_questions, cleaned_answers):\n",
    "    for word in str(q+a).split():\n",
    "        word_counts[word] += 1\n",
    "        if word_counts[word] > max_word_count:\n",
    "            max_word_count = word_counts[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_lower = 20 # Approx 5%\n",
    "thresh_upper = 500000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create word-index maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx_map = {}\n",
    "\n",
    "idx = 0\n",
    "for word, count in word_counts.items():\n",
    "    if thresh_lower<=count<=thresh_upper:\n",
    "        word_to_idx_map[word] = idx\n",
    "        idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_tokens = [\"<PAD>\", \"<EOS>\", \"<UNK>\", \"<SOS>\"] # Padding, End-of-string, Unknown-filtered out by threshold, Start-of-string\n",
    "for token in additional_tokens:\n",
    "    word_to_idx_map[token] = len(word_to_idx_map)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word_map = {idx:word for word,idx in word_to_idx_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add EOS token to all answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_answers_with_eos = [a+\" <EOS>\" for a in cleaned_answers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert questions and answers words to indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = word_to_idx_map.keys()\n",
    "questions_to_index = [[word_to_idx_map[w] if w in all_words else word_to_idx_map[\"<UNK>\"] for w in q.split()] for q in cleaned_questions]\n",
    "answers_to_index = [[word_to_idx_map[w] if w in all_words else word_to_idx_map[\"<UNK>\"] for w in a.split()] for a in cleaned_answers_with_eos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Truncate questions longer than threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 30\n",
    "sorted_questions_idx = []\n",
    "sorted_answers_idx = []\n",
    "sorted_questions = []\n",
    "sorted_answers = []\n",
    "\n",
    "for length in range(1,MAX_LEN):\n",
    "    for i,q in enumerate(questions_to_index):\n",
    "        if len(q)==length:\n",
    "            sorted_questions_idx.append(q)\n",
    "            sorted_answers_idx.append(answers_to_index[i])\n",
    "            sorted_questions.append(cleaned_questions[i])\n",
    "            sorted_answers.append(cleaned_answers_with_eos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(sorted_questions_idx, os.path.join(data_directory, \"questions_to_idx.h5\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
